{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from pyquantification.experiments import cached_experiments, DATASETS\n",
    "from pyquantification.evaluation import corrected_resampled_t_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quantification_methods = [\n",
    "    'count',\n",
    "    'pcc',\n",
    "    'em', \n",
    "    'gsls',\n",
    "    'true-weight-gsls',\n",
    "]\n",
    "gsls_df = cached_experiments(cache_key='gsls_results')\n",
    "prior_df = cached_experiments(cache_key='prior_shift_results')\n",
    "bins_df = cached_experiments(cache_key='bins_results')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_labels = {\n",
    "    'handwritten-letters-letter': 'HLL',\n",
    "    'handwritten-letters-author': 'HLA',\n",
    "    'arabic-digits': 'DIG',\n",
    "    'insect-sex': 'ISX',\n",
    "    'insect-species': 'ISP',\n",
    "}\n",
    "datasets = {\n",
    "    dataset_name: DATASETS[dataset_name]()\n",
    "    for dataset_name in dataset_labels.keys()\n",
    "}\n",
    "gain_weights = [0.0, 0.3, 0.7, 1.0]\n",
    "loss_weights = [0.0, 0.3, 0.7, 1.0]\n",
    "\n",
    "def print_table_latex(table_df):\n",
    "    for _, row in table_df.iterrows():\n",
    "        if row.isna().all():\n",
    "            print('\\hline')\n",
    "        else:\n",
    "            print(' & '.join(row.to_dict().values()) + r' \\\\')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def coverage_table():\n",
    "    plot_methods = {\n",
    "        'pcc': 'PCC',\n",
    "        'em': 'EM',\n",
    "        'gsls': 'GSLS',\n",
    "        'true-weight-gsls': 'TGSLS',\n",
    "    }\n",
    "\n",
    "    def format_cell(mean):\n",
    "        str_mean = f'{mean:.0%}'\n",
    "        str_mean = str_mean.replace('%', '\\%')\n",
    "        if mean >= 0.8:\n",
    "            str_mean = r'\\textbf{' + str_mean + '}'\n",
    "        return str_mean\n",
    "\n",
    "    rows = []\n",
    "    for dataset_name, dataset_label in dataset_labels.items():\n",
    "        for method, method_label in plot_methods.items():\n",
    "            row = {\n",
    "                'dataset': dataset_label,\n",
    "                'method': method_label,\n",
    "            }\n",
    "            for gain_weight in gain_weights:\n",
    "                for loss_weight in loss_weights:\n",
    "                    cell_gsls_df = gsls_df[\n",
    "                        (gsls_df['dataset_name'] == dataset_name) &\n",
    "                        (gsls_df['gain_weight'] == gain_weight) &\n",
    "                        (gsls_df['loss_weight'] == loss_weight)\n",
    "                    ]\n",
    "                    row[f'gw{gain_weight}, lw{loss_weight}'] = format_cell(cell_gsls_df[f'{method}_coverage'].mean())\n",
    "            if method == 'true-weight-gsls':\n",
    "                row['prior_shift'] = 'N.A.'\n",
    "            else:\n",
    "                cell_prior_df = prior_df[prior_df['dataset_name'] == dataset_name]\n",
    "                row['prior_shift'] = format_cell(cell_prior_df[f'{method}_coverage'].mean())\n",
    "            rows.append(row)\n",
    "        rows.append({})\n",
    "    return pd.DataFrame(rows)\n",
    "    \n",
    "table_df = coverage_table()\n",
    "display(table_df)\n",
    "print_table_latex(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def width_table():\n",
    "    t_test_alpha = 0.05\n",
    "    \n",
    "    def format_cell(mean, std, is_bold=False):\n",
    "        # Convert to percentage.\n",
    "        mean, std = mean * 100, std * 100\n",
    "\n",
    "        # Number formatting\n",
    "        mean_str = f'{mean:.0f}'\n",
    "        if std == 0.0:\n",
    "            std_str = '(0)'\n",
    "        elif std < 1:\n",
    "            std_str = r'(\\textless1)'\n",
    "        else:\n",
    "            std_str = f'({std:.0f})'\n",
    "\n",
    "        # Conditional boldface\n",
    "        if is_bold:\n",
    "            mean_str = r'\\textbf{' + mean_str + '}'\n",
    "            std_str = r'\\textbf{' + std_str + '}'\n",
    "\n",
    "        return f'{mean_str} & {std_str}'\n",
    "\n",
    "    rows = []\n",
    "    for dataset_name, dataset_label in dataset_labels.items():\n",
    "        est_row = {'dataset': dataset_label, 'method': 'GSLS'}\n",
    "        tru_row = {'dataset': dataset_label, 'method': 'TGSLS'}\n",
    "        dataset = datasets[dataset_name]\n",
    "        test_size = dataset.test_n / (dataset.test_n + dataset.train_n)\n",
    "        for gain_weight in gain_weights:\n",
    "            for loss_weight in loss_weights:\n",
    "                cell_df = gsls_df[\n",
    "                    (gsls_df['dataset_name'] == dataset_name) & \n",
    "                    (gsls_df['gain_weight'] == gain_weight) &\n",
    "                    (gsls_df['loss_weight'] == loss_weight)\n",
    "                ]\n",
    "                est_widths = cell_df[f'gsls_width']\n",
    "                tru_widths = cell_df[f'true-weight-gsls_width']\n",
    "                significant = corrected_resampled_t_test(est_widths.to_numpy(),\n",
    "                                                         tru_widths.to_numpy(),\n",
    "                                                         test_size=test_size) < t_test_alpha\n",
    "\n",
    "                cell_key = f'gw{gain_weight}, lw{loss_weight}'\n",
    "                est_row[cell_key] = format_cell(est_widths.mean(), est_widths.std(),\n",
    "                                                is_bold=(significant and (est_widths.mean() < tru_widths.mean())))\n",
    "                tru_row[cell_key] = format_cell(tru_widths.mean(), tru_widths.std(),\n",
    "                                                is_bold=(significant and (tru_widths.mean() < est_widths.mean())))\n",
    "        rows += [est_row, tru_row, {}]\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "table_df = width_table()\n",
    "display(table_df)\n",
    "print_table_latex(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def error_table():\n",
    "    t_test_alpha = 0.05\n",
    "    plot_methods = {\n",
    "        'count': 'CC',\n",
    "        'pcc': 'PCC',\n",
    "        'em': 'EM',\n",
    "        'gsls': 'GSLS',\n",
    "    }\n",
    "\n",
    "    def format_cell(mean, std, is_bold=False):\n",
    "        # Convert to percent\n",
    "        mean, std = mean * 100, std * 100\n",
    "        \n",
    "        # Number formatting\n",
    "        mean_str = f'{mean:.0f}'\n",
    "        if std == 0.0:\n",
    "            std_str = '(0)'\n",
    "        elif std < 1.0:\n",
    "            std_str = r'(\\textless1)'\n",
    "        else:\n",
    "            std_str = f'({std:.0f})'\n",
    "\n",
    "        # Conditional boldface\n",
    "        if is_bold:\n",
    "            mean_str = r'\\textbf{' + mean_str + '}'\n",
    "            std_str = r'\\textbf{' + std_str + '}'\n",
    "\n",
    "        return f'{mean_str} & {std_str}'\n",
    "    \n",
    "    def error_cell(df, method, test_size):\n",
    "        if method == 'count':\n",
    "            significant = False\n",
    "        else:\n",
    "            significant = corrected_resampled_t_test(df['count_absolute_error'].to_numpy(),\n",
    "                                                     df[f'{method}_absolute_error'].to_numpy(),\n",
    "                                                     test_size=test_size) < t_test_alpha\n",
    "        return format_cell(\n",
    "            df[f'{method}_absolute_error'].mean(),\n",
    "            df[f'{method}_absolute_error'].std(),\n",
    "            (significant and (df[f'{method}_absolute_error'].mean() < df['count_absolute_error'].mean()))\n",
    "        )\n",
    "\n",
    "    rows = []\n",
    "    for dataset_name, dataset_label in dataset_labels.items():\n",
    "        dataset = datasets[dataset_name]\n",
    "        test_size = dataset.test_n / (dataset.test_n + dataset.train_n)\n",
    "        for method, method_label in plot_methods.items():\n",
    "            row = {\n",
    "                'dataset': dataset_label,\n",
    "                'method': method_label,\n",
    "            }\n",
    "            \n",
    "            no_shift_df = gsls_df[\n",
    "                (gsls_df['dataset_name'] == dataset_name) &\n",
    "                ((gsls_df['gain_weight'] + gsls_df['loss_weight']) == 0.0)\n",
    "            ]\n",
    "            gsls_shift_df = gsls_df[\n",
    "                (gsls_df['dataset_name'] == dataset_name) &\n",
    "                ((gsls_df['gain_weight'] + gsls_df['loss_weight']) > 0.0)\n",
    "            ]\n",
    "            prior_shift_df = prior_df[\n",
    "                (prior_df['dataset_name'] == dataset_name)\n",
    "            ]\n",
    "            \n",
    "            row['no_shift'] = error_cell(no_shift_df, method, test_size)\n",
    "            row['gsls_shift'] = error_cell(gsls_shift_df, method, test_size)\n",
    "            row['prior_shift'] = error_cell(prior_shift_df, method, test_size)\n",
    "            rows.append(row)\n",
    "        rows.append({})\n",
    "    return pd.DataFrame(rows)\n",
    "    \n",
    "table_df = error_table()\n",
    "display(table_df)\n",
    "print_table_latex(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sensitivity_dataset_labels = {\n",
    "    'insect-sex': 'ISX-500',\n",
    "    'insect-sex_smaller': 'ISX-250',\n",
    "    'insect-sex_smallest': 'ISX-50',\n",
    "}\n",
    "class_count = 2\n",
    "sensitivity_bin_counts = [5, 'auto', 50]\n",
    "\n",
    "def runtime_table():\n",
    "    def format_cell(mean, std):\n",
    "        return f'{mean:.1f} & ({std:.1f})'\n",
    "\n",
    "    rows = []\n",
    "    for dataset_name, dataset_label in sensitivity_dataset_labels.items():\n",
    "        row = {'dataset': dataset_label}\n",
    "        for bin_count in sensitivity_bin_counts:\n",
    "            cell_df = bins_df[\n",
    "                (bins_df['dataset_name'] == dataset_name) &\n",
    "                (bins_df['bin_count'] == bin_count)\n",
    "            ]\n",
    "            # Convert to ms, and divide by number of classes computed in that time.\n",
    "            time_ms_series = cell_df['gsls_all_class_time_ns'] / 1_000_000 / class_count\n",
    "            row[f'{bin_count} bins'] = format_cell(\n",
    "                time_ms_series.mean(),\n",
    "                time_ms_series.std(),\n",
    "            )\n",
    "        rows.append(row)\n",
    "    return pd.DataFrame(rows)\n",
    "    \n",
    "table_df = runtime_table()\n",
    "display(table_df)\n",
    "print_table_latex(table_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
